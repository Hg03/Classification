{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc1cfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model, tree, ensemble, svm, neighbors, naive_bayes, neural_network, model_selection,impute,preprocessing,pipeline,compose\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "import joblib as jb\n",
    "\n",
    "cleanIt = jb.load('clean.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4337cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spaceTrain.csv')\n",
    "# removing useless columns\n",
    "features = df.drop(['PassengerId','Cabin','Name','Transported'],axis = 1)\n",
    "target = df.Transported\n",
    "numerical_features = [feat for feat in features if features[feat].dtypes !='O']\n",
    "categorical_features = [feat for feat in features if feat not in numerical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28f6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split your dataset into training and testing dataset\n",
    "x_train,x_test,y_train,y_test = model_selection.train_test_split(features,target,test_size = 0.2,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d3acb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.792409</td>\n",
       "      <td>0.792265</td>\n",
       "      <td>0.797532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stochastic Gradient</td>\n",
       "      <td>0.606671</td>\n",
       "      <td>0.606881</td>\n",
       "      <td>0.597173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.740081</td>\n",
       "      <td>0.739877</td>\n",
       "      <td>0.748330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.783209</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.782709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADABoost</td>\n",
       "      <td>0.791259</td>\n",
       "      <td>0.791063</td>\n",
       "      <td>0.797772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.790684</td>\n",
       "      <td>0.790440</td>\n",
       "      <td>0.798450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>0.783209</td>\n",
       "      <td>0.782530</td>\n",
       "      <td>0.802307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.687752</td>\n",
       "      <td>0.686182</td>\n",
       "      <td>0.743019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultiLayer Perceptron</td>\n",
       "      <td>0.781484</td>\n",
       "      <td>0.781170</td>\n",
       "      <td>0.791438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifiers  Accuracy Score   ROC_AUC        F1\n",
       "0    Logistic Regression        0.792409  0.792265  0.797532\n",
       "1    Stochastic Gradient        0.606671  0.606881  0.597173\n",
       "2          Decision Tree        0.740081  0.739877  0.748330\n",
       "3          Random Forest        0.783209  0.783270  0.782709\n",
       "4               ADABoost        0.791259  0.791063  0.797772\n",
       "5                XGBoost        0.790684  0.790440  0.798450\n",
       "6         Support Vector        0.783209  0.782530  0.802307\n",
       "7            Naive Bayes        0.687752  0.686182  0.743019\n",
       "8  MultiLayer Perceptron        0.781484  0.781170  0.791438"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_models(x_train,x_test,y_train,y_test):\n",
    "    score_table = {\n",
    "        'Classifiers': ['Logistic Regression','Stochastic Gradient','Decision Tree','Random Forest','ADABoost','XGBoost','Support Vector','Naive Bayes','MultiLayer Perceptron'],\n",
    "        'Accuracy Score':[],\n",
    "        'ROC_AUC':[],\n",
    "        'F1': []\n",
    "    }\n",
    "    models = {'Logreg':linear_model.LogisticRegression(),'sgd':linear_model.SGDClassifier(),'dt':tree.DecisionTreeClassifier(),'rf':ensemble.RandomForestClassifier(),'ada':ensemble.AdaBoostClassifier(),'xgb':XGBClassifier(),'sv':svm.SVC(),'nb':naive_bayes.GaussianNB(),'mlp':neural_network.MLPClassifier()}\n",
    "    for model in models:\n",
    "        models[model].fit(x_train.copy(),y_train.copy())\n",
    "        y_pred = models[model].predict(x_test.copy())\n",
    "        score_table['Accuracy Score'].append(metrics.accuracy_score(y_test.copy(),y_pred))\n",
    "        score_table['ROC_AUC'].append(metrics.roc_auc_score(y_test.copy(),y_pred))\n",
    "        score_table['F1'].append(metrics.f1_score(y_test.copy(),y_pred))\n",
    "        \n",
    "    return pd.DataFrame(score_table)\n",
    "\n",
    "compare_models(cleanIt.fit_transform(x_train),cleanIt.transform(x_test),y_train,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
